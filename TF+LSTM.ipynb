{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2V3G1VeLURZ",
        "outputId": "8da3c6e9-5a98-43bd-f42b-b67df2ea53f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/mypersonality_final.csv'\n",
        "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkuI7mKyLVcc",
        "outputId": "3dc63f00-ed15-40e7-c63f-49b39b023b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            #AUTHID  \\\n",
            "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
            "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
            "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
            "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
            "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
            "\n",
            "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
            "0                        likes the sound of thunder.  2.65   3.0  3.15  3.25   \n",
            "1  is so sleepy it's not even funny that's she ca...  2.65   3.0  3.15  3.25   \n",
            "2  is sore and wants the knot of muscles at the b...  2.65   3.0  3.15  3.25   \n",
            "3         likes how the day sounds in this new song.  2.65   3.0  3.15  3.25   \n",
            "4                                        is home. <3  2.65   3.0  3.15  3.25   \n",
            "\n",
            "   sOPN cEXT cNEU cAGR cCON cOPN               DATE  NETWORKSIZE  BETWEENNESS  \\\n",
            "0   4.4    n    y    n    n    y  06/19/09 03:21 PM        180.0      14861.6   \n",
            "1   4.4    n    y    n    n    y   07-02-2009 08:41        180.0      14861.6   \n",
            "2   4.4    n    y    n    n    y  06/15/09 01:15 PM        180.0      14861.6   \n",
            "3   4.4    n    y    n    n    y  06/22/09 04:48 AM        180.0      14861.6   \n",
            "4   4.4    n    y    n    n    y  07/20/09 02:31 AM        180.0      14861.6   \n",
            "\n",
            "   NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
            "0         93.29     0.03    15661.0        0.49           0.1  \n",
            "1         93.29     0.03    15661.0        0.49           0.1  \n",
            "2         93.29     0.03    15661.0        0.49           0.1  \n",
            "3         93.29     0.03    15661.0        0.49           0.1  \n",
            "4         93.29     0.03    15661.0        0.49           0.1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'STATUS' column is null\n",
        "df = df.dropna(subset=['STATUS'])\n",
        "\n",
        "# Fill missing values in the personality trait columns with the median value\n",
        "for col in ['sOPN', 'sCON', 'sEXT', 'sAGR', 'sNEU']:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Optional: If you want to replace the null 'STATUS' with an empty string instead of dropping\n",
        "# df['STATUS'] = df['STATUS'].fillna('')\n",
        "\n",
        "# Verify there are no more missing values\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnynO5vlLmWo",
        "outputId": "c2b24960-d6fe-49f6-9a12-2a956277784b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#AUTHID         0\n",
            "STATUS          0\n",
            "sEXT            0\n",
            "sNEU            0\n",
            "sAGR            0\n",
            "sCON            0\n",
            "sOPN            0\n",
            "cEXT            0\n",
            "cNEU            0\n",
            "cAGR            0\n",
            "cCON            0\n",
            "cOPN            0\n",
            "DATE            0\n",
            "NETWORKSIZE     0\n",
            "BETWEENNESS     0\n",
            "NBETWEENNESS    0\n",
            "DENSITY         0\n",
            "BROKERAGE       0\n",
            "NBROKERAGE      0\n",
            "TRANSITIVITY    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove punctuations\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove additional whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stop words\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the 'STATUS' column\n",
        "df['cleaned_status'] = df['STATUS'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "# Display the cleaned status\n",
        "df[['STATUS', 'cleaned_status']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "BrpP4UkfLoVF",
        "outputId": "6feddb36-0c38-4a05-bbf6-5c6f435c243d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              STATUS  \\\n",
              "0                        likes the sound of thunder.   \n",
              "1  is so sleepy it's not even funny that's she ca...   \n",
              "2  is sore and wants the knot of muscles at the b...   \n",
              "3         likes how the day sounds in this new song.   \n",
              "4                                        is home. <3   \n",
              "\n",
              "                                      cleaned_status  \n",
              "0                                likes sound thunder  \n",
              "1                        sleepy even funny get sleep  \n",
              "2  sore wants knot muscles base neck stop hurting...  \n",
              "3                          likes day sounds new song  \n",
              "4                                               home  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be111ad4-d0ea-4798-b564-ee1e04627fec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>cleaned_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>likes the sound of thunder.</td>\n",
              "      <td>likes sound thunder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
              "      <td>sleepy even funny get sleep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is sore and wants the knot of muscles at the b...</td>\n",
              "      <td>sore wants knot muscles base neck stop hurting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>likes how the day sounds in this new song.</td>\n",
              "      <td>likes day sounds new song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is home. &lt;3</td>\n",
              "      <td>home</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be111ad4-d0ea-4798-b564-ee1e04627fec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be111ad4-d0ea-4798-b564-ee1e04627fec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be111ad4-d0ea-4798-b564-ee1e04627fec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdebf176-98ae-4e25-96af-0af2ab703c1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdebf176-98ae-4e25-96af-0af2ab703c1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdebf176-98ae-4e25-96af-0af2ab703c1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['STATUS', 'cleaned_status']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"STATUS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"is so sleepy it's not even funny that's she can't get to sleep.\",\n          \"is home. <3\",\n          \"is sore and wants the knot of muscles at the base of her neck to stop hurting. On the other hand, YAY I'M IN ILLINOIS! <3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"sleepy even funny get sleep\",\n          \"home\",\n          \"sore wants knot muscles base neck stop hurting hand yay illinois\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize the tokenizer with a limit on the number of words\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "\n",
        "# Fit the tokenizer on the cleaned text\n",
        "tokenizer.fit_on_texts(df['cleaned_status'])\n",
        "\n",
        "# Convert text to sequences (integer encoding)\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_status'])\n",
        "\n",
        "# Display the first few tokenized sequences\n",
        "print(sequences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlZOV4w2Lp60",
        "outputId": "2cfb52c4-be4b-47b6-88cb-dcf15972f067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
            "[[762, 684, 763], [441, 56, 283, 8, 40], [510, 45, 4034, 2590, 1856, 1411, 143, 2591, 511, 78, 1857], [762, 3, 866, 12, 340], [24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = 100  # Define max length for padding\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Display the padded sequences\n",
        "print(padded_sequences[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBqCYZLrIK",
        "outputId": "bbecbba0-2c4d-4f3a-cdb6-c510c9056264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 762  684  763    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [ 441   56  283    8   40    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [ 510   45 4034 2590 1856 1411  143 2591  511   78 1857    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [ 762    3  866   12  340    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [  24    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming padded_sequences is already defined\n",
        "# Define the personality traits you want to model\n",
        "traits = ['sEXT', 'sNEU', 'sAGR', 'sCON', 'sOPN']\n",
        "\n",
        "# Store results for each trait\n",
        "results = {}\n",
        "\n",
        "# Loop through each trait\n",
        "for trait in traits:\n",
        "    # Define the target variable for the current trait\n",
        "    y = df[trait]\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Check the shape of the split datasets\n",
        "    print(f\"{trait} - Training set shape: {X_train.shape}, Test set shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "    # Here you can add your model training code for each trait\n",
        "    # For example:\n",
        "    # model.fit(X_train, y_train)\n",
        "    # y_pred = model.predict(X_test)\n",
        "    # You can calculate and store metrics here\n",
        "\n",
        "    # You might also want to store the results in the results dictionary\n",
        "    # results[trait] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1_score}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaeSEwBJLt1M",
        "outputId": "b0b0e892-dd57-4eb1-a52a-40ab9f40b6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sEXT - Training set shape: (3998, 100), Test set shape: (1000, 100), y_train shape: (3998,), y_test shape: (1000,)\n",
            "sNEU - Training set shape: (3998, 100), Test set shape: (1000, 100), y_train shape: (3998,), y_test shape: (1000,)\n",
            "sAGR - Training set shape: (3998, 100), Test set shape: (1000, 100), y_train shape: (3998,), y_test shape: (1000,)\n",
            "sCON - Training set shape: (3998, 100), Test set shape: (1000, 100), y_train shape: (3998,), y_test shape: (1000,)\n",
            "sOPN - Training set shape: (3998, 100), Test set shape: (1000, 100), y_train shape: (3998,), y_test shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wHj_phvLwe2",
        "outputId": "92bdaaf4-7d6a-42a2-ea8d-af26dd1fbbae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example threshold for binary classification\n",
        "threshold = 4  # Adjust this threshold for your data\n",
        "\n",
        "# List of personality traits to classify\n",
        "traits = ['sEXT', 'sNEU', 'sAGR', 'sOPN', 'sCON']\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100),\n",
        "    'XGBoost': xgb.XGBClassifier(n_estimators=100),\n",
        "    'CatBoost': CatBoostClassifier(iterations=100, silent=True)\n",
        "}\n",
        "\n",
        "# Split data into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_status'], df[traits], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize CountVectorizer and TfidfVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=10000)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "# Fit and transform for TF and TF-IDF\n",
        "X_train_tf = count_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tf = count_vectorizer.transform(X_test).toarray()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Simulating LSTM feature extraction\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding the sequences to ensure they are of equal length\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=200)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(200, 1)))  # Adjust input shape as needed\n",
        "model.add(Dense(1, activation='sigmoid'))  # Adjust based on binary or multi-class classification\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Store overall accuracies for each classifier\n",
        "overall_accuracies = {name: [] for name in classifiers.keys()}\n",
        "\n",
        "# Loop through each trait and convert the target to binary format\n",
        "for trait in traits:\n",
        "    # Convert the target variable to binary classes (discrete)\n",
        "    y_train_binary = (y_train[trait] > threshold).astype(int)\n",
        "    y_test_binary = (y_test[trait] > threshold).astype(int)\n",
        "\n",
        "    # Train the LSTM model for this trait\n",
        "    model.fit(X_train_padded, y_train_binary, epochs=5, batch_size=32)\n",
        "\n",
        "    # Extract LSTM features\n",
        "    X_train_lstm_features = model.predict(X_train_padded)\n",
        "    X_test_lstm_features = model.predict(X_test_padded)\n",
        "\n",
        "    # Combine TF and LSTM features\n",
        "    X_train_combined = np.hstack((X_train_tf, X_train_lstm_features))\n",
        "    X_test_combined = np.hstack((X_test_tf, X_test_lstm_features))\n",
        "\n",
        "    # Evaluate classifiers\n",
        "    print(f\"--- Evaluating classifiers for {trait} (TF + LSTM) ---\")\n",
        "    for name, classifier_model in classifiers.items():\n",
        "        classifier_model.fit(X_train_combined, y_train_binary)\n",
        "        accuracy = classifier_model.score(X_test_combined, y_test_binary)\n",
        "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Store accuracy for overall calculation\n",
        "        overall_accuracies[name].append(accuracy)\n",
        "\n",
        "# Calculate and print overall accuracy for each classifier\n",
        "print(\"\\n--- Overall Accuracy ---\")\n",
        "for name, accuracies in overall_accuracies.items():\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    print(f\"{name} Overall Accuracy (average): {avg_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i17AmaKIL1Oq",
        "outputId": "fc8b6f19-3ee3-4481-a3f5-5c133a3a1d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 233ms/step - accuracy: 0.7090 - loss: 0.6055\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.7144 - loss: 0.5953\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 247ms/step - accuracy: 0.7230 - loss: 0.5861\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 253ms/step - accuracy: 0.7166 - loss: 0.5906\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 237ms/step - accuracy: 0.7133 - loss: 0.5901\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step\n",
            "--- Evaluating classifiers for sEXT (TF + LSTM) ---\n",
            "AdaBoost Accuracy: 0.7120\n",
            "GradientBoosting Accuracy: 0.7300\n",
            "XGBoost Accuracy: 0.7180\n",
            "CatBoost Accuracy: 0.7300\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 234ms/step - accuracy: 0.9827 - loss: 0.1528\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 237ms/step - accuracy: 0.9850 - loss: 0.0748\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 240ms/step - accuracy: 0.9857 - loss: 0.0713\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 241ms/step - accuracy: 0.9836 - loss: 0.0777\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 236ms/step - accuracy: 0.9876 - loss: 0.0610\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step\n",
            "--- Evaluating classifiers for sNEU (TF + LSTM) ---\n",
            "AdaBoost Accuracy: 0.9860\n",
            "GradientBoosting Accuracy: 0.9830\n",
            "XGBoost Accuracy: 0.9890\n",
            "CatBoost Accuracy: 0.9900\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 236ms/step - accuracy: 0.7508 - loss: 0.6700\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.7431 - loss: 0.5690\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 234ms/step - accuracy: 0.7480 - loss: 0.5647\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.7471 - loss: 0.5613\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 234ms/step - accuracy: 0.7442 - loss: 0.5651\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step\n",
            "--- Evaluating classifiers for sAGR (TF + LSTM) ---\n",
            "AdaBoost Accuracy: 0.7560\n",
            "GradientBoosting Accuracy: 0.7600\n",
            "XGBoost Accuracy: 0.7440\n",
            "CatBoost Accuracy: 0.7590\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 234ms/step - accuracy: 0.5754 - loss: 0.7216\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.7007 - loss: 0.6044\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 238ms/step - accuracy: 0.7020 - loss: 0.6059\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.6995 - loss: 0.6032\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.7136 - loss: 0.5915\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step\n",
            "--- Evaluating classifiers for sOPN (TF + LSTM) ---\n",
            "AdaBoost Accuracy: 0.7120\n",
            "GradientBoosting Accuracy: 0.7070\n",
            "XGBoost Accuracy: 0.7160\n",
            "CatBoost Accuracy: 0.7050\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 231ms/step - accuracy: 0.6592 - loss: 0.6122\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 231ms/step - accuracy: 0.8192 - loss: 0.4726\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 232ms/step - accuracy: 0.8254 - loss: 0.4600\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 232ms/step - accuracy: 0.8284 - loss: 0.4574\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 236ms/step - accuracy: 0.8155 - loss: 0.4733\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step\n",
            "--- Evaluating classifiers for sCON (TF + LSTM) ---\n",
            "AdaBoost Accuracy: 0.8110\n",
            "GradientBoosting Accuracy: 0.8200\n",
            "XGBoost Accuracy: 0.8180\n",
            "CatBoost Accuracy: 0.8220\n",
            "\n",
            "--- Overall Accuracy ---\n",
            "AdaBoost Overall Accuracy (average): 0.7954\n",
            "GradientBoosting Overall Accuracy (average): 0.8000\n",
            "XGBoost Overall Accuracy (average): 0.7970\n",
            "CatBoost Overall Accuracy (average): 0.8012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example threshold for binary classification\n",
        "threshold = 4  # Adjust this threshold for your data\n",
        "\n",
        "# List of personality traits to classify\n",
        "traits = ['sEXT', 'sNEU', 'sAGR', 'sOPN', 'sCON']\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Split data into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_status'], df[traits], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize CountVectorizer and TfidfVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=10000)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "# Fit and transform for TF and TF-IDF\n",
        "X_train_tf = count_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tf = count_vectorizer.transform(X_test).toarray()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Simulating LSTM feature extraction\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding the sequences to ensure they are of equal length\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=200)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(200, 1)))  # Adjust input shape as needed\n",
        "model.add(Dense(1, activation='sigmoid'))  # Adjust based on binary or multi-class classification\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Store overall accuracies for RandomForest\n",
        "overall_accuracies = []\n",
        "\n",
        "# Loop through each trait and convert the target to binary format\n",
        "for trait in traits:\n",
        "    # Convert the target variable to binary classes (discrete)\n",
        "    y_train_binary = (y_train[trait] > threshold).astype(int)\n",
        "    y_test_binary = (y_test[trait] > threshold).astype(int)\n",
        "\n",
        "    # Train the LSTM model for this trait\n",
        "    model.fit(X_train_padded, y_train_binary, epochs=5, batch_size=32)\n",
        "\n",
        "    # Extract LSTM features\n",
        "    X_train_lstm_features = model.predict(X_train_padded)\n",
        "    X_test_lstm_features = model.predict(X_test_padded)\n",
        "\n",
        "    # Combine TF and LSTM features\n",
        "    X_train_combined = np.hstack((X_train_tf, X_train_lstm_features))\n",
        "    X_test_combined = np.hstack((X_test_tf, X_test_lstm_features))\n",
        "\n",
        "    # Evaluate RandomForest classifier\n",
        "    print(f\"--- Evaluating RandomForest for {trait} (TF + LSTM) ---\")\n",
        "    classifier.fit(X_train_combined, y_train_binary)\n",
        "    accuracy = classifier.score(X_test_combined, y_test_binary)\n",
        "    print(f\"RandomForest Accuracy for {trait}: {accuracy:.4f}\")\n",
        "\n",
        "    # Store accuracy for overall calculation\n",
        "    overall_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print overall accuracy for RandomForest\n",
        "avg_accuracy = np.mean(overall_accuracies)\n",
        "print(f\"\\nRandomForest Overall Accuracy (average): {avg_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "SI0H6RvQMIue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0895b92-9976-433f-eb03-7af1688ea23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 220ms/step - accuracy: 0.7017 - loss: 0.6082\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.7112 - loss: 0.5962\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 200ms/step - accuracy: 0.7138 - loss: 0.5898\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 204ms/step - accuracy: 0.7247 - loss: 0.5795\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 202ms/step - accuracy: 0.7178 - loss: 0.5858\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step\n",
            "--- Evaluating RandomForest for sEXT (TF + LSTM) ---\n",
            "RandomForest Accuracy for sEXT: 0.7270\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.9820 - loss: 0.1566\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 203ms/step - accuracy: 0.9808 - loss: 0.0945\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.9856 - loss: 0.0738\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 203ms/step - accuracy: 0.9829 - loss: 0.0838\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 200ms/step - accuracy: 0.9862 - loss: 0.0704\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step\n",
            "--- Evaluating RandomForest for sNEU (TF + LSTM) ---\n",
            "RandomForest Accuracy for sNEU: 0.9890\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 202ms/step - accuracy: 0.7446 - loss: 0.6415\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 204ms/step - accuracy: 0.7544 - loss: 0.5570\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 205ms/step - accuracy: 0.7484 - loss: 0.5641\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 194ms/step - accuracy: 0.7460 - loss: 0.5644\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 194ms/step - accuracy: 0.7509 - loss: 0.5602\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step\n",
            "--- Evaluating RandomForest for sAGR (TF + LSTM) ---\n",
            "RandomForest Accuracy for sAGR: 0.7640\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.5682 - loss: 0.7271\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 220ms/step - accuracy: 0.7162 - loss: 0.5932\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.7213 - loss: 0.5920\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 200ms/step - accuracy: 0.6970 - loss: 0.6059\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 203ms/step - accuracy: 0.7136 - loss: 0.5924\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step\n",
            "--- Evaluating RandomForest for sOPN (TF + LSTM) ---\n",
            "RandomForest Accuracy for sOPN: 0.7290\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 204ms/step - accuracy: 0.6258 - loss: 0.6489\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - accuracy: 0.8171 - loss: 0.4746\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 202ms/step - accuracy: 0.8258 - loss: 0.4590\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 202ms/step - accuracy: 0.8296 - loss: 0.4523\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 202ms/step - accuracy: 0.8216 - loss: 0.4664\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n",
            "--- Evaluating RandomForest for sCON (TF + LSTM) ---\n",
            "RandomForest Accuracy for sCON: 0.8130\n",
            "\n",
            "RandomForest Overall Accuracy (average): 0.8044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1c8AaCNus0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}